---
tags:
  - llm
  - AI
  - Pretrain
date: 2024-06-12T21:39:00
---
# 背景

目前，虽然开源模型仍与闭源模型（Openai的gpt系列，豆包系列，通义千问Max等）有差距，但也有Qwen（dense模型）、Deepseek（MOE模型）、MiniCPM（端侧小模型）等优秀模型。对于个人以及业务团队，在资源有效的情况下很难训出相同size下更优秀的模型，那么在这个背景下我们进行pretrain的意义又有哪些呢？

1. 各大公司更多是开源模型参数（对于全开源的，性能也和只开源参数的相差较大），但并没有开源训练框架、训练数据、训练策略等核心的内容，本质上还是闭源的。因此，在基模全面走向开源前，还是有必要掌握pretrain的技术。
2. 对于业务团队来说，更现实来说通用模型变现能力是远不如domain模型的，这也导致了continue-pretrain的需要日益增大，而continue-pretrain和pretrain是类似的，并没有本质上区别
3. 如果不进行pretrain，必然无法得知模型在pretrain阶段喂入什么数据，各种数据的精确配比、各种能力程度，这些是仅依靠评估无法衡量得出的。这也会导致在sft阶段不知道合适的数据配比loss下降不理想，并且在alignment阶段没办法针对性解决问题，从而无法激发模型最大潜力。（幻觉、公司价值观等）
4. 使用开源模型，tokenizer是不可控的，这会带来解码速度问题。像23年最早只有llama开源模型，但模型本身词表是没有中文的，这会导致使用llama进行中文迁移时解码速度慢。即使是现在qwen模型，在客服业务场景中，补充一些抖音的信息和客服信息的toekn，增加业务场景文本压缩率，也能提高编码效率。

# 数据

## 数据爬取

1. 数据量级
	pretrain模型，第一件需要准备的事就是获取大量数据（10T+原数据），当然也可以是增量式的，即边训模型边找。

2. 数据获取
	获取方式：爬虫爬网页、逛淘宝（知网等）、数据贩子等等

	高质量数据，比如论文书籍等，往往不是纯文本而是pdf格式，调用效果好的pdf服务。自己手搓的python库解析，稍微涉及公式、表格、排版的pdf，解析效果都不行。gpt解析准确率还行，但价格略贵于pdf解析服务，更多可以尝试做增量服务。当然也可以训ocr模型，这也是很多pretrain团队的方案。

3. 通用数据
	当然，网上通用的数据集已经很多：FineWeb、Pile、Skypile、C4、RedPajama、Wukong等。但换一个角度，这些开源的中文大模型数据集，必然不是最干净的数据，在质量上都有问题。（之前商汤&上海AiLab有一个处理的pipeline，对这批数据处理后，还是会处理掉不小比例）（即使认为干净下载huggingface数据，服务器往往不连外网，只能换成hf mirror，下载数据还是很慢，需要好几天。基本是手动split要下载的数据合集，起多个进程在多台服务器上下载。同时下载完，文件数量大的ls都卡，更别想vim来简单查看了，还是需要大数据集群来做进一步数据处理）

	并且数据是有知识密度的差异，高知识密度往往是开源数据不具备的（钞能力）。并且还有一个思路是合成数据，也就是对低知识密度数据进行合成，把几千字的低知识密度合成几百字的高知识密度数据给到模型，变相于训练速度提升10倍！

## 数据清洗

1. 打分器
	利用模型对pretrain数据的质量进行打分，已经是数据清洗的标配。这在llama系列和qwen系列技术报告中都有提及。并且对于pretrain这种只有text（不涉及conversations）的数据，是更适合使用bert系列模型的。在同等size下，bert结构模型的表征能力强于decoder-only模型，因此业界更多是从bert系列中选一个来训。

	并且对打分器来说，都会给code（markdown、latex等）格式数据打分低。所以，往往需要将这类数据区分出来，并且打分器也是分领域的，不同领域下需要设置不同阈值。并且打分器，可以不用执着于准确率，一个是时间和成本的考虑，另一个则是打分器的结果只是大量数据特征中的一个特征，不是完全依赖打分器的。

2. 规则
	相对于打分器，另一个重要清洗策略则是规则。以下是一些常见规则：
	1. 数据长度
	2. 数据中某个token（字符）占比
	3. 数据的中文占比、英文占比、数字占比
	4. 数据中是否有超链接等字段
	5. 数据中是否有一些低质量关键词
	6. 数据中是否包含反动词汇、色情词汇等

	但同时不能完全信任规则，基于规则可能让数据分布有偏。例如：认为包含网址的数据质量低，但网址基本是英文，这样可能就把英文占比高的数据都过滤掉了，从一个中英双语模型变成中文单语模型。还是需要多用vim进行检验过滤出去的文本

3. 脱敏
	还有一个则是数据脱敏，尽可能把数据中设计人名、工号、电话号码、邮箱等信息剔除出去。

## 数据去重

能否不去重？答案是否定的，除非是只采用单一开源预训练数据集。网上基本所有开源数据都是来自common crawl，即使只使用单一数据源或者爬取数据，也不难发现这个现象：网页A引用网页B，网页B引用网页C...最后又引用回网页A。即使是不同网页，也很难保证不是同一份内容被知乎、CSDN、小红书等软件反正转载。

1. 去重粒度
	去重工作粒度可以分为sentence去重或者document去重，这个目前没有统一结论。当然如果可以sentence去重是最好，但是数据量和工作难度会陡增。

	去重肯定需要大数据处理集群，不管是hadoop还是spark，只要是一个map/reduce框架就可以。

	在商汤的做法是对于短文本使用余弦相似度去重，对于长文本使用MinHash算法去重，并且使用分桶操作减少计算量，桶间使用重叠来减小分桶带来的影响。（如果只是用python for循环实现过于低效。在商汤不会这些工具，硬用大数据集群从0-1手搓了一个清洗pipeline）
2. 去重数量
	去重后剩余数量以及去重粒度是根据训练所需要数据量决定的，是时间和成本的tradeoff，去重工作是没有尽头的。所以先要明确训练所需的数据量，根据数据量决定需要卡相似度的阈值。
3. 去重质量
	目前还没有结论来指导一条数据在pretrain阶段训练多少次对模型最友好，因此选择去重粒度小，去重质量没有那么高影响也没想象中大。可以通过让相似文本之间间隔尽可能多token来减小影响。


## 数据配比

1. 数据分类
	在数据清洗和配比的时候，都是需要根据不同数据类型来决定阈值的。一般pretrain需要对每一个document进行类别判断，不用特别精准，把数据分为：数学、代码、百科、新闻等类目。分类器还是bert系列即可。

	在清洗时候：代码数学和新闻类文本，当然是会使用不同阈值来判断是否高质量

	在去重时候：对于新闻类知识密度相对较低的，可能70%重复度就需要丢弃，对于书籍类知识密度相对较高的，则可以进一步放宽可能80%重复度才丢弃。并且优先保留数据打分器得分比较高的数据。
2. 数据配比
	在大部分技术报告中，都会提及自己的数据配比，基本都是需要保证代码+逻辑+知识，其中知识部分会进行中英文的区分，逻辑部分可以认为是math数据和一些cot数据的结合体（但个人感官上math code logic三部分数据越来越混杂）。对于一个中文模型来说，从语言上来说中：英：code=4：4：2一般是比较常见的

对于英文是否必要，可以根据情况决定，但在商汤的经验是英文的比例一定不能低，甚至略多于中文都更好。（在llama 1基础上做通用ct+sft，在通用的榜单上评测。如果只是用中文数据，基本只能保证中文相关的小幅度提升，英文掉点；如果只使用英文数据，其中可能有小量中英翻译数据，基本是都小幅度提升；如果数据中英文略多于中文，基本是英文不掉点同时中文大幅度提升）

原因：中文语料在干净程度和数据量级上，都无法与英文语料相比，尤其是数学、代码、逻辑等被认为是高质量的数据

## 数据顺序

1. 课程学习
	pretrain的本质是教模型学知识的过程，既然是学习就涉及到学习知识的顺序，一般都是先学简单再学难，这也是Curriculum Learning（CL，课程学习）的核心思想。课程学习本质是：对于同样的训练数据，通过调整训练数据得到的不同模型，能力是不同的。

	虽然预测next token的训练方式，让模型可以学会每一条数据，但是会有灾难性遗忘的可能性。假设A是困难知识，B是简单知识。对于A+B的学习顺序，可能导致A知识遗忘30%，B+A的学习顺序，可能导致B知识遗忘20%，那后者学习顺序遗忘的少，自然模型能力也强。并且从分布上说B出现次数会远多于A，即使B遗忘了由于比较简单且出现次数多，也会被回忆起来。

	所以一个经验性做法是将Pretrain分为两个Stage，在Stage one让模型尽可能多学习知识，在Stage two（退火阶段）增加math code等高质量数据比例，并且加入sft数据（甚至是benchmark）让模型来续写，从而提升模型表现。
2. In context pretrain
	llama的In Context Pretrain个人感觉是比较激进的，但落到客服领域有一些可以采取和改进的点：
	1. 同一通会话以及重复进行的会话在语义上是更相关的，将这些进行拼接从而构成语义更加连贯的上下文
	2. 但llama认为在同一条pretrain中无关的文本相互不能看见，在实际应用中和下游任务中这是矛盾的。大部分用户不会切换一个新话题就起一个新的聊天窗口。用户也不会问完一个问题要问其他问题就退出和客服对话窗口，然后重新进入希望分配到一个新客服。模型是需要具备切换topic能力和判断上下文信息和当前信息是否相关的能力。

## 数据Pipeline

1. 数据处理
	数据是动态加载的，并且会提前做好tokenization和concatenation。考虑到一般pretrain会有两个stage，stage two会复用stage one的数据，那么应该在part-xxx.jsonl中记录这些信息。
2. 模型训练
	虽然模型训练可以笼统的分为two stage，但训崩的可能（loss炸、数据配比有问题等）以及是否可能更好执行课程学习呢？
